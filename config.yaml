options:
  gateway-port:
    type: int
    default: 18789
    description: Port for the OpenClaw Gateway WebSocket/HTTP server
  
  gateway-bind:
    type: string
    default: loopback
    description: |
      Gateway bind mode: 'loopback' (127.0.0.1 only), 'lan' (all interfaces), 
      or specific IP address.
      
      IMPORTANT: Multi-unit deployments REQUIRE 'lan' mode for Node connectivity.
      The charm will block deployment if loopback mode is used with multiple units.
  
  node-version:
    type: string
    default: "24"
    description: Node.js major version to install (minimum 22 required)
  
  ai-provider:
    type: string
    default: ""
    description: |
      Primary AI model provider. Supported providers:
      - anthropic: Anthropic Claude models
      - openai: OpenAI GPT models  
      - openai-codex: OpenAI Codex (requires OAuth)
      - google: Google Gemini models
      - opencode: OpenCode Zen models
      - github-copilot: GitHub Copilot/Models API
      - openrouter: OpenRouter aggregator
      - xai: xAI models
      - groq: Groq models
      - cerebras: Cerebras models
      - mistral: Mistral AI models
      - zai: Z.AI (GLM) models
      - vercel-ai-gateway: Vercel AI Gateway
      - ollama: Local Ollama models (no API key needed)
      - bedrock: AWS Bedrock (uses AWS credentials)
  
  ai-model:
    type: string
    default: ""
    description: |
      AI model(s) to use. Supports:
      - Single model: claude-opus-4-5
      - Multiple models (comma-separated): gemini-3-flash-preview,gemini-3-pro-preview,gemini-2.5-pro
      
      When multiple models are provided:
      - First model becomes the primary (system default)
      - Remaining models are added as fallbacks
      - All models use the configured ai-provider
      
      Models are stored as provider/model format (e.g., anthropic/claude-opus-4-5).
      
      For models from different providers, use separate slots (ai0-provider/ai0-model, etc.)
      with each provider's API key.
      
      Examples:
      - Single: claude-opus-4-5
      - Multiple same provider: gpt-4,gpt-3.5-turbo,gpt-4o-mini
      - GitHub Copilot aggregator: gemini-3-flash-preview,claude-haiku-4.5,gpt-4
  
  ai-api-key:
    type: string
    default: ""
    description: |
      API key for the selected AI provider. Required for most providers:
      - anthropic: Anthropic API key
      - openai: OpenAI API key
      - google: Google Gemini API key
      - opencode: OpenCode API key
      - github-copilot: GitHub personal access token
      - openrouter: OpenRouter API key
      - xai: xAI API key
      - groq: Groq API key
      - cerebras: Cerebras API key
      - mistral: Mistral API key
      - zai: Z.AI API key
      - vercel-ai-gateway: Vercel AI Gateway API key
      Not required for: ollama (local), bedrock (AWS credentials), openai-codex (OAuth)
      
      Note: API keys are stored securely in auth-profiles.json, not in environment variables.
  
  ai-base-url:
    type: string
    default: ""
    description: |
      Custom API base URL for OpenAI-compatible providers. 
      Use this to connect to local AI services like LM Studio, vLLM, FastChat, etc.
      Examples:
      - LM Studio: http://localhost:1234/v1
      - vLLM: http://localhost:8000/v1
      - Text Generation WebUI: http://localhost:5000/v1
      Leave empty to use default provider endpoints.
  
  # Additional AI models (ai0 through ai9) for multi-model support
  ai0-provider:
    type: string
    default: ""
    description: |
      AI provider for model slot 0. See ai-provider for supported providers.
  
  ai0-model:
    type: string
    default: ""
    description: |
      AI model(s) for slot 0. Supports single or comma-separated models.
      All models in this slot use ai0-provider.
      Example: gpt-4,gpt-3.5-turbo,gpt-4o-mini
  
  ai0-api-key:
    type: string
    default: ""
    description: API key for AI model slot 0
  
  ai0-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 0 (for OpenAI-compatible local services)
  
  ai1-provider:
    type: string
    default: ""
    description: AI provider for model slot 1. See ai-provider for supported providers.
  
  ai1-model:
    type: string
    default: ""
    description: AI model(s) for slot 1 (supports comma-separated)
  
  ai1-api-key:
    type: string
    default: ""
    description: API key for AI model slot 1
  
  ai1-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 1 (for OpenAI-compatible local services)
  
  ai2-provider:
    type: string
    default: ""
    description: AI provider for model slot 2. See ai-provider for supported providers.
  
  ai2-model:
    type: string
    default: ""
    description: AI model(s) for slot 2 (supports comma-separated)
  
  ai2-api-key:
    type: string
    default: ""
    description: API key for AI model slot 2
  
  ai2-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 2 (for OpenAI-compatible local services)
  
  ai3-provider:
    type: string
    default: ""
    description: AI provider for model slot 3. See ai-provider for supported providers.
  
  ai3-model:
    type: string
    default: ""
    description: AI model(s) for slot 3 (supports comma-separated)
  
  ai3-api-key:
    type: string
    default: ""
    description: API key for AI model slot 3
  
  ai3-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 3 (for OpenAI-compatible local services)
  
  ai4-provider:
    type: string
    default: ""
    description: AI provider for model slot 4. See ai-provider for supported providers.
  
  ai4-model:
    type: string
    default: ""
    description: AI model(s) for slot 4 (supports comma-separated)
  
  ai4-api-key:
    type: string
    default: ""
    description: API key for AI model slot 4
  
  ai4-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 4 (for OpenAI-compatible local services)
  
  ai5-provider:
    type: string
    default: ""
    description: AI provider for model slot 5. See ai-provider for supported providers.
  
  ai5-model:
    type: string
    default: ""
    description: AI model(s) for slot 5 (supports comma-separated)
  
  ai5-api-key:
    type: string
    default: ""
    description: API key for AI model slot 5
  
  ai5-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 5 (for OpenAI-compatible local services)
  
  ai6-provider:
    type: string
    default: ""
    description: AI provider for model slot 6. See ai-provider for supported providers.
  
  ai6-model:
    type: string
    default: ""
    description: AI model(s) for slot 6 (supports comma-separated)
  
  ai6-api-key:
    type: string
    default: ""
    description: API key for AI model slot 6
  
  ai6-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 6 (for OpenAI-compatible local services)
  
  ai7-provider:
    type: string
    default: ""
    description: AI provider for model slot 7. See ai-provider for supported providers.
  
  ai7-model:
    type: string
    default: ""
    description: AI model(s) for slot 7 (supports comma-separated)
  
  ai7-api-key:
    type: string
    default: ""
    description: API key for AI model slot 7
  
  ai7-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 7 (for OpenAI-compatible local services)
  
  ai8-provider:
    type: string
    default: ""
    description: AI provider for model slot 8. See ai-provider for supported providers.
  
  ai8-model:
    type: string
    default: ""
    description: AI model(s) for slot 8 (supports comma-separated)
  
  ai8-api-key:
    type: string
    default: ""
    description: API key for AI model slot 8
  
  ai8-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 8 (for OpenAI-compatible local services)
  
  ai9-provider:
    type: string
    default: ""
    description: AI provider for model slot 9. See ai-provider for supported providers.
  
  ai9-model:
    type: string
    default: ""
    description: AI model(s) for slot 9 (supports comma-separated)
  
  ai9-api-key:
    type: string
    default: ""
    description: API key for AI model slot 9
  
  ai9-base-url:
    type: string
    default: ""
    description: Custom API base URL for AI model slot 9 (for OpenAI-compatible local services)
  
  telegram-bot-token:
    type: string
    default: ""
    description: |
      Telegram bot token from @BotFather (e.g., 123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11).
      Leave empty to disable Telegram messaging.
  
  discord-bot-token:
    type: string
    default: ""
    description: |
      Discord bot token from Discord Developer Portal.
      Leave empty to disable Discord messaging.
  
  slack-bot-token:
    type: string
    default: ""
    description: |
      Slack bot token (xoxb-...) from Slack App settings.
      Leave empty to disable Slack messaging.
  
  slack-app-token:
    type: string
    default: ""
    description: |
      Slack app token (xapp-...) from Slack App settings.
      Required when slack-bot-token is configured.
  
  line-channel-access-token:
    type: string
    default: ""
    description: |
      LINE Messaging API channel access token from LINE Developers Console.
      Leave empty to disable LINE messaging.
  
  line-channel-secret:
    type: string
    default: ""
    description: |
      LINE Messaging API channel secret from LINE Developers Console.
      Required when line-channel-access-token is configured.
  
  dm-policy:
    type: string
    default: pairing
    description: |
      DM access policy: 'pairing' (require pairing code), 'open' (auto-respond), 
      or 'closed' (reject all DMs)
  
  dm-scope:
    type: string
    default: main
    description: |
      DM session scope for isolating direct message conversations:
      - 'main' (default): All DMs share the main session for continuity across devices/channels
      - 'per-peer': Isolate sessions by sender ID across channels
      - 'per-channel-peer': Isolate by channel + sender (recommended for multi-user inboxes)
      - 'per-account-channel-peer': Isolate by account + channel + sender (recommended for multi-account inboxes)
      
      Security Warning: If your agent receives DMs from multiple people, use 'per-channel-peer'
      or 'per-account-channel-peer' to prevent conversation context leakage between users.
  
  sandbox-mode:
    type: string
    default: non-main
    description: |
      Sandbox mode for non-main sessions: 'all' (sandbox everything), 
      'non-main' (sandbox groups/channels), or 'none' (no sandboxing)
  
  install-method:
    type: string
    default: npm
    description: |
      Installation method: 'npm' (global npm install), 'pnpm' (uses npm), 
      'bun' (global bun install), or 'source' (build from git source)
  
  version:
    type: string
    default: latest
    description: OpenClaw version to install (e.g., 'latest', '2026.1.29', or git commit)
  
  auto-update:
    type: boolean
    default: false
    description: Automatically update OpenClaw to latest stable version on upgrade-charm
  
  use-browser:
    type: string
    default: ""
    description: |
      Browser to install for browser automation. OpenClaw's browser tool
      enables web browsing, screenshots, and automation via Playwright.
      Supported values: 'chrome', 'chromium', 'firefox', or empty string to disable.
      Can be changed post-deployment via 'juju config'.
  
  log-level:
    type: string
    default: info
    description: Log level (debug, info, warn, error)
  
  manual:
    type: boolean
    default: false
    description: |
      Manual configuration mode. When enabled (manual=true):
      - Charm will NOT auto-generate openclaw.json or node.json
      - User is responsible for creating and managing OpenClaw configuration
      - Charm only installs OpenClaw and manages systemd services
      - Peer relations still work for multi-unit deployments
      - Environment file (.openclaw/environment) is still created for systemd
      
      When disabled (manual=false, default):
      - Charm auto-generates configuration from Juju config options
      - AI providers, channels, and settings are managed by the charm
      - Configuration updates on 'juju config' changes
